/* Generated by Streams Studio: January 16, 2016 at 5:49:12 AM EST */
package application;


import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;

import java.net.InetAddress;
import java.util.Iterator;
import java.util.Queue;

import org.apache.log4j.Logger;
import org.elasticsearch.action.bulk.BulkRequestBuilder;
import org.elasticsearch.action.bulk.BulkResponse;
import org.elasticsearch.action.index.IndexRequestBuilder;
import org.elasticsearch.client.Client;
import org.elasticsearch.client.transport.TransportClient;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.common.transport.InetSocketTransportAddress;
import org.elasticsearch.common.xcontent.XContentBuilder;

import com.ibm.streams.operator.Attribute;
import com.ibm.streams.operator.OperatorContext;
import com.ibm.streams.operator.StreamSchema;
import com.ibm.streams.operator.StreamingData.Punctuation;
import com.ibm.streams.operator.StreamingInput;
import com.ibm.streams.operator.Tuple;
import com.ibm.streams.operator.model.InputPortSet;
import com.ibm.streams.operator.model.InputPortSet.WindowMode;
import com.ibm.streams.operator.model.InputPortSet.WindowPunctuationInputMode;
import com.ibm.streams.operator.model.InputPorts;
import com.ibm.streams.operator.model.Libraries;
import com.ibm.streams.operator.model.Parameter;
import com.ibm.streams.operator.model.PrimitiveOperator;
import com.ibm.streams.operator.samples.patterns.TupleConsumer;

/**
 * Class for an operator that consumes tuples and does not produce an output stream. 
 * This pattern supports a number of input streams and no output streams. 
 * <P>
 * The following event methods from the Operator interface can be called:
 * </p>
 * <ul>
 * <li><code>initialize()</code> to perform operator initialization</li>
 * <li>allPortsReady() notification indicates the operator's ports are ready to process and submit tuples</li> 
 * <li>process() handles a tuple arriving on an input port 
 * <li>processPuncuation() handles a punctuation mark arriving on an input port 
 * <li>shutdown() to shutdown the operator. A shutdown request may occur at any time, 
 * such as a request to stop a PE or cancel a job. 
 * Thus the shutdown() may occur while the operator is processing tuples, punctuation marks, 
 * or even during port ready notification.</li>
 * </ul>
 * <p>With the exception of operator initialization, all the other events may occur concurrently with each other, 
 * which lead to these methods being called concurrently by different threads.</p> 
 */
@PrimitiveOperator(name="ElasticSink", namespace="application",description="Java Operator ElasticSink")
//@Icons(location16="icons/operator_icon16.gif", location32="icons/operator_icon32.gif")
@InputPorts({@InputPortSet(description="Port that ingests tuples", cardinality=1, optional=false, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious), @InputPortSet(description="Optional input ports", optional=true, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious)})
@Libraries({"impl/java/lib/*"})
public class ElasticSink extends TupleConsumer {
	
	private String elasticHost = null;
	private Client client = null;
	private String clusterName = "elasticsearch";
	
	private String indexName = null;
	private String dataType = null;
	private static final Logger trace = Logger.getLogger(ElasticSink.class.getName());
	
    /**
     * Initialize this operator. Called once before any tuples are processed.
     * @param context OperatorContext for this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
	@Override
	public synchronized void initialize(OperatorContext context) throws Exception {
    	// Must call super.initialize(context) to correctly setup an operator.
		super.initialize(context);
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " initializing in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
        
        setBatchSize(batchSize());
        
        Settings settings = Settings.settingsBuilder().put("cluster.name", clusterName).build();   
        
        client = TransportClient.builder().settings(settings).build().addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(elasticHost), 9300));
        trace.info("client created");
	}
	
	 protected int batchSize() {
		 return getBatchSize();
		     
	 }
	 
    /**
     * Notification that initialization is complete and all input and output ports 
     * are connected and ready to receive and submit tuples.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public synchronized void allPortsReady() throws Exception {
    	// This method is commonly used by source operators. 
    	// Operators that process incoming tuples generally do not need this notification. 
        OperatorContext context = getOperatorContext();
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " all ports are ready in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
    }

    /**
     * Process an incoming tuple that arrived on the specified port.
     * @param stream Port the tuple is arriving on.
     * @param tuple Object representing the incoming tuple.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    /*
    @Override
    public void process(StreamingInput<Tuple> stream, Tuple tuple)
            throws Exception {
    }
    */
    
    /**
     * Process an incoming punctuation that arrived on the specified port.
     * @param stream Port the punctuation is arriving on.
     * @param mark The punctuation mark
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public void processPunctuation(StreamingInput<Tuple> stream,
    		Punctuation mark) throws Exception {
    	// TODO: If window punctuations are meaningful to the external system or data store, 
    	// insert code here to process the incoming punctuation.
    }

    
    
    // Mandatory parameter elasticHost mapping to the Java bean property id
    @Parameter(name="elasticHost", optional=false)
    public void setId(String elasticHost) {
        this.elasticHost = elasticHost;
    }
    
    // Mandatory parameter elasticHost mapping to the Java bean property id
    @Parameter(name="clusterName", optional=true)
    public void setClusterName(String clusterName) {
        this.clusterName = clusterName;
    }
    
    // Mandatory parameter elasticHost mapping to the Java bean property id
    @Parameter(name="indexName", optional=false)
    public void setIndexName(String indexName) {
        this.indexName = indexName;
    }
    
    @Parameter(name="dataType", optional=false)
    public void setDataType(String dataType) {
        this.dataType = dataType;
    }
    
    /**
     * Shutdown this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public synchronized void shutdown() throws Exception {
        OperatorContext context = getOperatorContext();
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " shutting down in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
        
        // TODO: If needed, close connections or release resources related to any external system or data store.
        trace.info("shutdown");
        // Must call super.shutdown()
        if(client!=null){
        	client.close();
        } else {
        	trace.error("client was null");
        }
        super.shutdown();
    }

	@Override
	protected boolean processBatch(Queue<BatchedTuple> batch) throws Exception {
		trace.info("process batch");
		BulkRequestBuilder bulkRequest = client.prepareBulk();
		
	
		int tuplesInRequest = 0;
		for (Iterator<BatchedTuple> iter = batch.iterator(); iter.hasNext(); ) {
			if (tuplesInRequest++ == getBatchSize()){
				break;
			}
			BatchedTuple item = iter.next();
			iter.remove();
			StreamSchema schema = item.getStream().getStreamSchema();
			
			IndexRequestBuilder irb = client.prepareIndex(indexName, dataType, "1");
			
			XContentBuilder json = jsonBuilder().startObject();
			 
			for (Attribute attribute : schema) {
				 json.field(attribute.getName(), item.getTuple().getString(attribute.getName()));
			}
			
			json.endObject();
			irb.setSource(json);
			bulkRequest.add(irb);
			
		}
		
		BulkResponse bulkResponse = bulkRequest.get();
		if (bulkResponse.hasFailures()) {
		    // process failures by iterating through each bulk response item
		}
		return true;
	}
    
}
